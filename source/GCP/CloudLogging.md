# Cloud Logging
GCPのログ収集・管理サービス。各種サービスから集まるログの保管・分析・モニタリングを一手に引き受ける。
[Cloud Logging](https://cloud.google.com/logging#documentation)

本記事では以下の流れで整理
- ログはどうやって集まるのか？ – 各サービスのログ収集の仕組みと、まずすべてのログが Cloud Logging に集約される流れ
- どのサービス由来かをどう見分けるのか？ – ログエントリに付与される resource.type と ラベルによる自動分類
- どうやってアラートにつなげるのか？ – Cloud Monitoring と連携したログベースのメトリクスとアラートポリシー設定


## ログの収集
Cloud Logging は GCP 上で発生したすべてのログを一箇所に集約する仕組み。Compute Engine（GCE）や GKE、Cloud Run、Cloud Functions といった主要サービスのログは、特別な設定をしなくても自動的に Cloud Logging に収集される。

例えば GKE では、各ノードにデプロイされたログ収集エージェント（Ops エージェント）がコンテナの標準出力・エラー出力を監視し、付加情報（メタデータ）をつけて Cloud Logging に送信する。
そのため、アプリケーションがコンテナ上で stdout や stderr に出力したログは自動的に Logging に蓄積される。Cloud Run や Cloud Functions も同様に、サービスの実行環境が標準出力などに書き出したログを自動で収集し Cloud Logging に送信する。

一方、オンプレミスやカスタムアプリケーションのログ、あるいはファイルに直接出力しているログなど自動収集の対象外となるログについても、Cloud Logging に送信する方法が用意されている。例えば GCEのVM 上で動くアプリケーションのログファイルは Ops エージェントを導入してログパイプラインを設定することで収集可能。
また、任意のプログラムから Cloud Logging API を使ってログを書き込むこともできる。
こうした方法で「それ以外のログもすべてまず Cloud Logging に集める」ことが可能となる。

## Cloud Logging のログエントリ構造（全体像）
Cloud Loggingで収集されたログで出力される項目は以下が主要なものになる。

|項目名|意味 / 役割|出力内容の例|補足|
|:----|:----|:----|:----|
|timestamp|ログ発生時刻|2025-01-01T12:00:00Z|実行時刻。遅延送信でも保持|
|severity|ログレベル|DEBUG / INFO / ERROR|Monitoring アラートと直結|
|logName|ログの論理的分類|projects/xxx/logs/stdout|stdout / stderr / custom|
|resource.type|発生元サービス種別|k8s_container|GKE / Cloud Run 判別の要|
|resource.labels|リソース識別情報|cluster_name, pod_name|自動付与される|
|textPayload|非構造化ログ本文|order failed|プレーンテキスト|
|jsonPayload|構造化ログ本文|{ "order_id": 123 }|検索・分析に最適|
|labels|任意の補助メタ情報|env=prod|ユーザー定義|
|trace|Cloud Trace ID|projects/.../traces/...|分散トレーシング|
|spanId|Trace 内のスパン|a1b2c3|マイクロサービス向け|
|httpRequest|HTTP リクエスト情報|status / latency|L7 ログで自動付与|


## resource.typeとlabel
Cloud Logging に全ログが集まった後、重要になるのが各ログエントリに付加される **リソースタイプ (resource.type)** と **ラベル (labels)** 。
これらは「そのログがどのサービスのどのリソースから来たか」を示す情報で、GCP が自動で付与するメタデータであり、アプリケーション開発者や運用者が個別に設定する必要はなく、GCP側でログごとに適切なリソースタイプとラベルが割り当てらる。
[監視対象のリソースとサービス](https://cloud.google.com/logging/docs/api/v2/resource-list)

代表的なresource.typeとlabelを整理すると以下。

|サービス|リソースタイプ (resource.type)|主なリソースラベル (resource.labels 等)|
|:----|:----|:----|
|GKE（コンテナログ）|k8s_container|クラスタ名、Namespace名、Pod名、コンテナ名、ロケーション（リージョン/ゾーン）|
|Cloud Run（サービス）|cloud_run_revision|サービス名、リビジョン名、リージョン（※）|
|Cloud Run（ジョブ）|cloud_run_job|ジョブ名、実行名（Execution）、タスク番号（インデックス）、リージョン|
|Cloud Functions|cloud_function|関数名、リージョン|

これらの情報のおかげで、「このログはどのプロジェクトのどのサービス・どのリソースから出力されたものか」を機械的に判別で可能。
クラスタ名やサービス名、関数名などが自動でログに紐づくため、後述するフィルタで「どのクラスタのログだけを見る」「どのCloud Runサービスのエラーのみ抽出する」といった絞り込みが簡単に行える。


## フィルタリング
Cloud Logging でログを検索したりログをエクスポート（後述のシンク）する際には、ログフィルタ（クエリ）を記述して条件を指定する。
フィルタの書式は比較的シンプルだが、効果的に使うためには以下の順序で条件を組み立てるとよい。

- リソースタイプ (resource.type) で大枠を絞る  
    - まず対象とするサービスやリソースの種類を限定。
    - 例えば「GKE のコンテナログ」に絞るなら resource.type="k8s_container" のように指定。
    - こうすることで関係ないサービスのログを一気に除外することができる。
- 必要に応じてラベルでリソース個別に絞る  
    - リソースタイプ内でさらに特定のリソースだけに絞りたい場合は、該当するラベルを条件に加える。
    - 例えば GKE ならクラスタ名やネームスペース名、Cloud Run ならサービス名などを指定することでさらにログを限定。
- ログ内容やレベル（severity）で条件追加  
    - 最後に、ログの本文中に含まれるキーワードや、ログレベル（INFO、ERRORなど）による絞り込み条件を追加。
    - メッセージ中の文字列マッチは textPayload:"文字列" のようにダブルクオートで囲んで指定し、ログレベルの指定は例えば severity>=ERROR のように表現する。

この順序でフィルタを書くことで、まず対象のログ種別を限定し（大量のログから目的のサービス関連ログだけを選出）、次に必要なら個別リソースまで絞り、最後に内容レベルで条件を課す、といった効率的な検索が可能。

### フィルタ記述の例
GKE において Namespace が "backend" の Pod から出力された ERROR レベル以上のログだけを検索する場合:  
「GKEコンテナのログ」の中から「Namespaceがbackendのもの」に限定し、さらにログレベルが ERROR 以上（ERRORやCRITICAL、ALERTなど）のログだけを対象にする。
実際のフィルタ文字列では改行は論理積（AND）として扱われ、すべての条件を満たすログエントリのみが結果に残る。
```
resource.type="k8s_container"
resource.labels.namespace_name="backend"
severity>=ERROR
```

Cloud Run Job のログの中から、メッセージに特定のエラーID（例：e.abc.）を含むものだけをカウントしたい場合:  
Cloud Run Job の実行ログから 'e.abc.' という文字列が本文中に現れるログを抽出するフィルタ。
```
resource.type="cloud_run_job"
textPayload:"e.abc."
```

さらに、特定のサフィックス（例えば e.abc.001）を除外したい場合、除外条件としてハイフン（-）を先頭に付けた条件を追加可能。
以下のように記載すると 'e.abc.' を含むログのうち 'e.abc.001' を含むものは除外され、001以外のIDで終わるログだけがヒットする。
```
resource.type="cloud_run_job"
textPayload:"e.abc."
-textPayload:"e.abc.001"
```

このように、Cloud Logging のクエリ言語では 包含条件はそのまま、除外条件は先頭に - を付けて指定。
また大文字小文字は基本区別されない（正規表現を除く）。
なお、ログのJSONペイロード内のフィールド（構造化ログの場合）も jsonPayload.フィールド名="値" のように指定可能で、柔軟な検索が可能。


## アラート
Cloud Logging 単体では、ログを閲覧・検索・フィルタリングすることができるが、ログ発の通知（アラート） 機能は持っていない。
そこで活用するのが Cloud Monitoring との連携。
Logging と Monitoring は統合されたオブザーバビリティ基盤の一部であり、Logging のデータをもとに Monitoring 側でアラートを発報できる。

ログによるアラートを実現する一般的な方法は「ログベースの指標（ログベースメトリクス）」を作り、それに対してアラートポリシーを設定するという手順。
[ログベースのアラート ポリシーを構成する](https://cloud.google.com/logging/docs/alerting/log-based-alerts?hl=ja)


具体的には次の3ステップによる設定を行う。
- ログフィルタを作成  
    - まずアラートのトリガーとしたいログを抽出するフィルタ条件を決める
        - 先の例でいえば、Cloud Run Job のログから特定のエラーID (e.abc.) を含み、かつ無視してよいID (e.abc.001) は除外するといったフィルタを作る
        - 例: resource.type="cloud_run_job" textPayload:"e.abc." -textPayload:"e.abc.001"
        - このフィルタは後続のメトリクスとアラートで共通して利用
- ログベースメトリクスを作成  
    - 作成したフィルタを元にカウンタ型のメトリクスを定義
        - メトリクスの種類は「Counter（カウンタ）」を選択し、フィルタにマッチするログエントリを1件検出するごとにカウントが1増えるように設定
        - こうして Logging 内でログに基づくメトリクスが生成されると、Cloud Monitoring 側からそのメトリクスの時系列データを参照できるようになる
        - 例えば上記フィルタにマッチするログが1件発生すればメトリクスが「1」を記録し、発生しない間は「0」のまま推移するようなイメージ
- アラートポリシーを設定  
    - Cloud Monitoring のアラートポリシーで、上述のログベースメトリクスに対ししきい値条件を設定
        - 例えば「直近5分間で該当メトリクスの値が1以上になったら（= 該当ログが1件でも発生したら）アラート発報」という条件を作成
        - しきい値を 0→1 に超えたタイミングで即アラート発生、のように設定すれば、対象ログが出力された事実をリアルタイムに捉えて通知可能
        - 通知先には Slack や Email、PagerDuty など様々なチャネルを指定可能


## シンク設定（エクスポート）
Cloud Logging に蓄積されたログは、必要に応じて他のストレージやシステムにエクスポート（転送）することも可能。
これを実現するのが ログシンク (Log Sink) 機能。
Logging の ログルーター (Logs Router) は受け取った各ログエントリを内部で評価し、プロジェクトごとに設定されたシンクの条件にマッチしたものを指定の出力先にコピー・転送する。

主な出力先として、以下のような Google Cloud サービスがサポートされている。
シンク設定は Logging の「ログルーター」画面から行え、対象とするログ（フィルタ条件）と出力先を指定。デフォルトではプロジェクト毎に _Default というシンクがあり、すべてのログが Cloud Logging のバケットに保存される設定になっている。追加でシンクを作成することで、特定のログだけ別途エクスポートしたり、すべてのログを複製して他システムに送信するといったことが可能になる。

- BigQuery – ログを BigQuery のデータセットにエクスポートできます。これにより、ログデータをSQLでクエリし高度な分析を行ったり、長期間（Cloud Loggingの標準保持期間以上に）データを保持してトレンドを分析したりできる。例えば1年間分のアプリケーションログを BigQuery に貯めておき、後からエラーの発生傾向を統計的に調べる、といった使い方が可能。
- Cloud Storage – ログを Cloud Storage バケットにエクスポートすれば、アーカイブとして長期保存したり、生ログファイルとして保管できる。規制遵守や監査の目的でログを削除せず保管したい場合に有用。また、圧縮・ライフサイクル管理など Cloud Storage の機能を活用してコスト効率よく保存できる。
- Pub/Sub – ログを Pub/Sub トピックにストリーミング配信することもできる。Pub/Sub に流したログは独自のログ処理パイプラインやサードパーティ製の解析基盤に連携可能。たとえばリアルタイムにログを Pub/Sub 経由でデータ処理基盤（DatadogやSplunk、自社の分析システムなど）に送り込み、モニタリングや機械学習のフィードとするといった応用ができる。
