# CloudOps

## Cloud Logging
GCPのログ収集・管理サービス。各種サービスから集まるログの保管・分析・モニタリングを一手に引き受ける。
[Cloud Logging](https://cloud.google.com/logging#documentation)

本記事では以下の流れで整理
- ログはどうやって集まるのか？ – 各サービスのログ収集の仕組みと、まずすべてのログが Cloud Logging に集約される流れ
- どのサービス由来かをどう見分けるのか？ – ログエントリに付与される resource.type と ラベルによる自動分類
- どうやってアラートにつなげるのか？ – Cloud Monitoring と連携したログベースのメトリクスとアラートポリシー設定


### ログの収集
Cloud Logging は GCP 上で発生したすべてのログを一箇所に集約する仕組み。Compute Engine（GCE）や GKE、Cloud Run、Cloud Functions といった主要サービスのログは、特別な設定をしなくても自動的に Cloud Logging に収集される。

例えば GKE では、各ノードにデプロイされたログ収集エージェント（Ops エージェント）がコンテナの標準出力・エラー出力を監視し、付加情報（メタデータ）をつけて Cloud Logging に送信する。
そのため、アプリケーションがコンテナ上で stdout や stderr に出力したログは自動的に Logging に蓄積される。Cloud Run や Cloud Functions も同様に、サービスの実行環境が標準出力などに書き出したログを自動で収集し Cloud Logging に送信する。

一方、オンプレミスやカスタムアプリケーションのログ、あるいはファイルに直接出力しているログなど自動収集の対象外となるログについても、Cloud Logging に送信する方法が用意されている。例えば GCEのVM 上で動くアプリケーションのログファイルは Ops エージェントを導入してログパイプラインを設定することで収集可能。
また、任意のプログラムから Cloud Logging API を使ってログを書き込むこともできる。
こうした方法で「それ以外のログもすべてまず Cloud Logging に集める」ことが可能となる。

### Cloud Logging のログエントリ構造（全体像）
Cloud Loggingで収集されたログで出力される項目は以下が主要なものになる。

|大分類（所属）|中分類|項目名|意味 / 役割|出力例|補足|
|:----|:----|:----|:----|:----|:----|
|LogEntry メタ情報|識別|insertId|ログ一意ID|1abcd1234|重複排除用|
| |時刻|timestamp|ログ発生時刻|2025-01-01T12:00:00Z|遅延送信でも保持|
| |重要度|severity|ログレベル|INFO / ERROR|Monitoringと直結|
| |分類|logName|ログの論理名|projects/xxx/logs/stdout|stdout / stderr / custom|
|発生元リソース|種別|resource.type|どのサービス由来か|k8s_container|最重要フィールド|
| |識別|resource.labels|リソース固有情報|cluster / pod / container|自動付与|
|補助メタ情報|ラベル|labels|追加のキー情報|env=prod|検索・整理用|
|ログ本文（Payload）|非構造|textPayload|プレーンテキスト|order failed|grep的検索|
| |構造化|jsonPayload|JSONログ本文|{ "order_id": 123 }|分析・集計向き|
|分散トレース|Trace|trace|Trace ID|projects/.../traces/...|Cloud Trace連携|
| |Span|spanId|スパンID|a1b2c3|マイクロサービス|
|HTTP 情報|L7|httpRequest|HTTP詳細|status / latency|LB / Run / Ingress|

jso形式の例では以下となる
```
{
    "insertId": "1abcd1234",
    "timestamp": "2025-01-01T12:00:00.123456Z",
    "severity": "ERROR",
    "logName": "projects/my-project/logs/stdout",

    "resource": {
        "type": "k8s_container",
        "labels": {
            "project_id": "my-project",
            "location": "asia-northeast1",
            "cluster_name": "prod-cluster",
            "namespace_name": "default",
            "pod_name": "orders-api-7c9f9d6d5b-abcde",
            "container_name": "orders-api"
        }
    },

    "labels": {
        "compute.googleapis.com/resource_name": "gke-prod-cluster-default-pool-12345"
    },

    "textPayload": "order failed: database timeout",
    "jsonPayload": {
    "order_id": 123,
    "user_id": "u-999",
    "error": "timeout"
    }

    "trace": "projects/my-project/traces/105445aa7843bc8bf206b120001000",
    "spanId": "a1b2c3d4e5f6",

    "httpRequest": {
        "requestMethod": "POST",
        "requestUrl": "/orders",
        "status": 500,
        "latency": "1.234s",
        "userAgent": "curl/8.0"
    }
}
```


### resource.typeとlabel
Cloud Logging に全ログが集まった後、重要になるのが各ログエントリに付加される **リソースタイプ (resource.type)** と **ラベル (labels)** 。
これらは「そのログがどのサービスのどのリソースから来たか」を示す情報で、GCP が自動で付与するメタデータであり、アプリケーション開発者や運用者が個別に設定する必要はなく、GCP側でログごとに適切なリソースタイプとラベルが割り当てらる。
[監視対象のリソースとサービス](https://cloud.google.com/logging/docs/api/v2/resource-list)

代表的なresource.typeとlabelを整理すると以下。

|サービス|resource.type|階層|対応する resource.labels|
|:----|:----|:----|:----|
|GKE|k8s_container|Cluster|cluster_name|
| | |Namespace|namespace_name|
| | |Pod|pod_name|
| | |Container|container_name|
| | |Location|location|
|Cloud Run（Service）|cloud_run_revision|Service|service_name|
| | |Revision|revision_name|
| | |Location|location|
|Cloud Run（Job）|cloud_run_job|Job|job_name|
| | |Execution|execution_name|
| | |Task|task_index|
| | |Location|location|
|Cloud Functions|cloud_function|Function|function_name|
| | |Location|location|


これらの情報のおかげで、「このログはどのプロジェクトのどのサービス・どのリソースから出力されたものか」を機械的に判別で可能。
クラスタ名やサービス名、関数名などが自動でログに紐づくため、後述するフィルタで「どのクラスタのログだけを見る」「どのCloud Runサービスのエラーのみ抽出する」といった絞り込みが簡単に行える。


### フィルタリング
Cloud Logging では、ログの検索やログシンク（BigQuery / Pub/Sub などへのエクスポート）を行う際に
ログフィルタ（クエリ） を記述して対象ログを指定する。

Cloud Logging のクエリでは、改行は論理積（AND）として扱われる。
```
resource.type="k8s_container"
resource.labels.namespace_name="backend"
severity>=ERROR
```
これは次の意味を持つ：
- GKE コンテナログのうち、
- Namespace が backend で、
- かつ ERROR 以上のログだけを表示する

#### フィルタの記述例
Cloud Run Job のログから特定エラーIDを含むものを抽出
```
resource.type="cloud_run_job"
textPayload:"e.abc."
```
- Cloud Run Job の実行ログのみ
- メッセージ本文に e.abc. を含むログを検索

特定のエラーIDだけを除外する
```
resource.type="cloud_run_job"
textPayload:"e.abc."
-textPayload:"e.abc.001"
```
- e.abc. を含むログは対象
- ただし e.abc.001 を含むものは除外


#### 構造化ログ（jsonPayload）の検索
アプリケーションが JSON 形式でログを出力している場合、フィールド単位での検索が可能になる。
```
jsonPayload.order_id=123
jsonPayload.error_code="TIMEOUT"
```
- フィールド検索
- インデックスが効く
- 集計・メトリクス化に最適

#### フィルタ演算子の整理
Cloud Logging のフィルタでは、
「どのフィールドに対して検索しているか」 によって使える演算子と意味が変わる。

特に混乱しやすいのが、
- = と =~
- :（payload検索）
の使い分け。

結論としては以下を意識する。
- 構造化されたフィールド（resource / labels / jsonPayloadのフィールド）
    - → = / >= / =~ を使う
- ログ本文（文字列）
    - → : を使う
- 除外したい条件
    - → 先頭に - を付ける

|用途|対象フィールド|書き方|意味|補足|
|:----|:----|:----|:----|:----|
|完全一致|resource / labels / jsonPayload.<field>|=|値が完全一致|インデックスが効く|
|範囲比較|severity / timestamp|>=|大小比較|ERROR以上など|
|正規表現|resource / labels / jsonPayload.<field>|=~|正規表現一致|prefix検索で多用|
|文字列包含|textPayload / jsonPayload.<field>|:|部分一致（含む）|grep的検索|
|除外条件|すべて|-条件|NOT 条件|組み合わせ可|

### アラート
Cloud Logging 単体では、ログを閲覧・検索・フィルタリングすることができるが、ログ発の通知（アラート） 機能は持っていない。
そこで活用するのが Cloud Monitoring との連携。
Logging と Monitoring は統合されたオブザーバビリティ基盤の一部であり、Logging のデータをもとに Monitoring 側でアラートを発報できる。

ログによるアラートを実現する一般的な方法は「ログベースの指標（ログベースメトリクス）」を作り、それに対してアラートポリシーを設定するという手順。
[ログベースのアラート ポリシーを構成する](https://cloud.google.com/logging/docs/alerting/log-based-alerts?hl=ja)


具体的には次の3ステップによる設定を行う。
- ログフィルタを作成  
    - まずアラートのトリガーとしたいログを抽出するフィルタ条件を決める
        - 先の例でいえば、Cloud Run Job のログから特定のエラーID (e.abc.) を含み、かつ無視してよいID (e.abc.001) は除外するといったフィルタを作る
        - 例: resource.type="cloud_run_job" textPayload:"e.abc." -textPayload:"e.abc.001"
        - このフィルタは後続のメトリクスとアラートで共通して利用
- ログベースメトリクスを作成  
    - 作成したフィルタを元にカウンタ型のメトリクスを定義
        - メトリクスの種類は「Counter（カウンタ）」を選択し、フィルタにマッチするログエントリを1件検出するごとにカウントが1増えるように設定
        - こうして Logging 内でログに基づくメトリクスが生成されると、Cloud Monitoring 側からそのメトリクスの時系列データを参照できるようになる
        - 例えば上記フィルタにマッチするログが1件発生すればメトリクスが「1」を記録し、発生しない間は「0」のまま推移するようなイメージ
- アラートポリシーを設定  
    - Cloud Monitoring のアラートポリシーで、上述のログベースメトリクスに対ししきい値条件を設定
        - 例えば「直近5分間で該当メトリクスの値が1以上になったら（= 該当ログが1件でも発生したら）アラート発報」という条件を作成
        - しきい値を 0→1 に超えたタイミングで即アラート発生、のように設定すれば、対象ログが出力された事実をリアルタイムに捉えて通知可能
        - 通知先には Slack や Email、PagerDuty など様々なチャネルを指定可能


### シンク設定（エクスポート）
Cloud Logging に蓄積されたログは、必要に応じて他のストレージやシステムにエクスポート（転送）することも可能。
これを実現するのが ログシンク (Log Sink) 機能。
Logging の ログルーター (Logs Router) は受け取った各ログエントリを内部で評価し、プロジェクトごとに設定されたシンクの条件にマッチしたものを指定の出力先にコピー・転送する。

主な出力先として、以下のような Google Cloud サービスがサポートされている。
シンク設定は Logging の「ログルーター」画面から行え、対象とするログ（フィルタ条件）と出力先を指定。デフォルトではプロジェクト毎に _Default というシンクがあり、すべてのログが Cloud Logging のバケットに保存される設定になっている。追加でシンクを作成することで、特定のログだけ別途エクスポートしたり、すべてのログを複製して他システムに送信するといったことが可能になる。

- BigQuery – ログを BigQuery のデータセットにエクスポートできます。これにより、ログデータをSQLでクエリし高度な分析を行ったり、長期間（Cloud Loggingの標準保持期間以上に）データを保持してトレンドを分析したりできる。例えば1年間分のアプリケーションログを BigQuery に貯めておき、後からエラーの発生傾向を統計的に調べる、といった使い方が可能。
- Cloud Storage – ログを Cloud Storage バケットにエクスポートすれば、アーカイブとして長期保存したり、生ログファイルとして保管できる。規制遵守や監査の目的でログを削除せず保管したい場合に有用。また、圧縮・ライフサイクル管理など Cloud Storage の機能を活用してコスト効率よく保存できる。
- Pub/Sub – ログを Pub/Sub トピックにストリーミング配信することもできる。Pub/Sub に流したログは独自のログ処理パイプラインやサードパーティ製の解析基盤に連携可能。たとえばリアルタイムにログを Pub/Sub 経由でデータ処理基盤（DatadogやSplunk、自社の分析システムなど）に送り込み、モニタリングや機械学習のフィードとするといった応用ができる。
